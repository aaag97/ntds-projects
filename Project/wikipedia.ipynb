{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "wikipedia.set_lang('en') # setting wikipedia language\n",
    "import wikipediaapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from time import sleep\n",
    "import sys\n",
    "\n",
    "import nltk # for nlp on articles\n",
    "#nltk.download(\"stopwords\")\n",
    "#nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAquisitionUtils():\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_category_members(category_members, level=0, max_level=1):\n",
    "        \"\"\"\n",
    "        Function to take all article in category (max_level control the depth of articles taken from the subcategories)\n",
    "        Arguments:\n",
    "        category_members - a list of category members\n",
    "        level - the level at which to start getting articles\n",
    "        max_level - the maximal level for the fetched articles\n",
    "        Returns:\n",
    "        list_articles - a list of the desired articles\n",
    "        \"\"\"\n",
    "#         return 0\n",
    "        list_articles = []\n",
    "        for c in category_members.values():\n",
    "            if c.ns == 0:\n",
    "                list_articles.append(c) \n",
    "                #print(\"%s: %s (ns: %d)\" % (\"*\" * (level + 1), c.title, c.ns))\n",
    "            elif level < max_level and c.ns == 14:\n",
    "                sub_list = []\n",
    "                sub_list = DataAquisitionUtils.fetch_category_members(c.categorymembers, level=level + 1, max_level=max_level)\n",
    "                list_articles = list_articles + sub_list\n",
    "        return list_articles\n",
    "\n",
    "    @staticmethod\n",
    "    def hyperlinks_matrix(list_articles):\n",
    "        \"\"\"\n",
    "        Computes an adjacency matrix with the hyperlinks between the different articles in the argument given\n",
    "        Arguments:\n",
    "        list_articles - a list of articles for which to compute the hyperlink matrix\n",
    "        Returns:\n",
    "        matrix - a binary matrix A where A[i,j] = 1 if article i has a hyperlinkt to article j, and A[i,j] = 0 otherwise\n",
    "        \"\"\"\n",
    "        len_time = len(list_articles)*0.05\n",
    "        matrix = np.zeros((len(list_articles), len(list_articles)))\n",
    "        compt = 0\n",
    "        for article in list_articles:\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(compt/len_time), int(5*compt/len_time)))\n",
    "            sys.stdout.flush()\n",
    "            sleep(0.25)\n",
    "            for link in article.links:\n",
    "                for i in range(len(list_articles)):\n",
    "                    if (link == list_articles[i].title):\n",
    "                        matrix[compt,i] = 1\n",
    "            compt = compt + 1\n",
    "        return matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def take_words(list_articles, stop_words, is_title = False):\n",
    "        \"\"\"\n",
    "        Function that tokenizes and returns all words in the list of articles given\n",
    "        Arguments:\n",
    "        list_articles - list of articles\n",
    "        is_title - whether the list contains pages or just strings of titles\n",
    "        Returns:\n",
    "        words_df - the words in the articles in a dataframe\n",
    "        \"\"\"\n",
    "        words_df = pd.DataFrame(columns=['article', 'words'])\n",
    "        for i in range(len(list_articles)):\n",
    "            if (i%100 == 0) :\n",
    "                print(i)\n",
    "            try: \n",
    "                if (is_title == False):\n",
    "                    page = wikipedia.page(list_articles[i].title)\n",
    "                else:\n",
    "                    page = wikipedia.page(list_articles[i])\n",
    "            except wikipedia.DisambiguationError as e:\n",
    "                s = e.options\n",
    "                s = list(filter(lambda x : x != \"\", s))\n",
    "                try :\n",
    "                    page = wikipedia.page(s)\n",
    "                except wikipedia.DisambiguationError as e:\n",
    "                    pass\n",
    "            except wikipedia.PageError:\n",
    "                pass\n",
    "            words = word_tokenize(page.content)\n",
    "            words = [elem.lower() for elem in words]\n",
    "            words = [elem for elem in words if len(elem) > 1 and elem.isdigit() == False]\n",
    "            words_wostop = [x for x in words if x not in stop_words]\n",
    "            words_wostop = [elem.lower() for elem in words_wostop]\n",
    "            if (is_title == False):\n",
    "                words_df.loc[i] = [list_articles[i].title] + [words_wostop]\n",
    "            else:\n",
    "                words_df.loc[i] = [list_articles[i]] + [words_wostop]\n",
    "        return words_df\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def make_features(words, important_words_df, weights = True):\n",
    "#         explode_df = words.explode('words')\n",
    "#         if (weights == True) :\n",
    "#             explode_df = explode_df.merge(important_words_df, on = 'words', how = 'right')\n",
    "#             df = pd.DataFrame(words['article']).assign(key = 1).merge(pd.DataFrame(important_words_df['words']).assign(key = 1), on = 'key').drop('key', 1)\n",
    "#             df2 = df.merge(explode_df, on = ['article','words'] , how = 'left').drop_duplicates().fillna(0)\n",
    "#             df3 = pd.pivot_table(df2, values = 'tfidf',  index = 'article', columns=['words'])\n",
    "#         else : \n",
    "#             explode_df['exist'] = np.ones(len(explode_df))\n",
    "#             df = pd.DataFrame(words['article']).assign(key = 1).merge(pd.DataFrame(important_words_df['words']).assign(key = 1), on = 'key').drop('key', 1)\n",
    "#             df2 = df.merge(explode_df, on = ['article','words'] , how = 'left').drop_duplicates().fillna(0)\n",
    "#             df3 = pd.pivot_table(df2, values = 'exist',  index = 'article', columns=['words'])\n",
    "#         display(df3.head(10))\n",
    "#         features = df3.values\n",
    "#         return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPUtilities():\n",
    "    \n",
    "    @staticmethod\n",
    "    def TF_IDF(words_df, nb_words):\n",
    "        \"\"\"\n",
    "        Function to get the words with the top TF-IDF scores\n",
    "        Arguments:\n",
    "        words_df - the dataframe consisting of the words to be considered\n",
    "        nb_words - the number of words we would like the function to return\n",
    "        Returns:\n",
    "        df - a dataframe containing the words with the best TF-IDF scores\n",
    "        \"\"\"\n",
    "        #remove strings like \"10,000\"\n",
    "        #religion_df['words'] = religion_df['words'].apply(lambda word_list: list(filter(lambda word: (',' not in word), word_list)))\n",
    "        #only keep strings that contain alphabet chars\n",
    "        words_df['words'] = words_df['words'].apply(lambda word_list: list(filter(lambda word: word.isalpha(), word_list)))\n",
    "        # create a column with all words concatenated\n",
    "        words_df['words_string'] = words_df['words'].apply(lambda words_list: \" \".join(words_list))\n",
    "\n",
    "        cv=CountVectorizer()\n",
    "        word_count_vector=cv.fit_transform(words_df['words_string'])\n",
    "\n",
    "        tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "        tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "        # count matrix\n",
    "        count_vector=cv.transform(words_df['words_string'])\n",
    "\n",
    "        # tf-idf scores\n",
    "        tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "\n",
    "        feature_names = cv.get_feature_names()\n",
    "        \n",
    "        dense = tf_idf_vector.todense()\n",
    "        denselist = dense.tolist()\n",
    "                \n",
    "        #tf_idf = matrix where rows are articles and columns are words and values are tfidf score for word in article\n",
    "        tf_idf = pd.DataFrame(data=denselist, columns=feature_names, index=words_df['article'])\n",
    "        \n",
    "        #these are the words that have the biggest tfidf score\n",
    "        important_words = pd.DataFrame(tf_idf.sum(axis=0, numeric_only=True).sort_values(ascending = False),\\\n",
    "                                  columns=['tfidf']).head(nb_words).index.values\n",
    "        \n",
    "        #only keep the most important words in matrix\n",
    "        tf_idf = tf_idf[important_words]\n",
    "\n",
    "        return tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the articles of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquire = DataAquisitionUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia('en') # getting articles in english\n",
    "# fetching the articles for categories of interest\n",
    "religion_page = wiki_wiki.page(\"Category:Religion\")\n",
    "science_page = wiki_wiki.page(\"Category:Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE IF YOU DO NOT HAVE PICKLES\n",
    "# religion_articles = aquire.fetch_category_members(religion_page.categorymembers,0,1)\n",
    "# science_articles = aquire.fetch_category_members(science_page.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion_articles = pd.read_pickle('./religion_articles')\n",
    "science_articles = pd.read_pickle('./science_articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperlink matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE IF YOU DO NOT HAVE CSV\n",
    "# list_articles = religion_articles + science_articles\n",
    "# adjacency_matrix = aquire.hyperlinks_matrix(list_articles)\n",
    "# num_edges = np.count_nonzero(adjacency_matrix)\n",
    "# print(f\"Number of edges in the feature graph: {num_edges}\")\n",
    "# np.savetxt('hyperlinks.csv', adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./hyperlinks.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the words with the highest TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take all the words present in the articles that are not stopwords\n",
    "stop_found = ['====', '===', '==', '<<', '>>', \"''\", '``', \"'s\" , '\\displaystyle', '...', '\\phi', '\\mu', '\\mathbf', '--', 'x_',\n",
    "        '\\alpha', '\\dot', '\\hat', '\\lambda', '\\left', '\\right', 'mathcal', '\\nu', '\\partial'] #getting the stopwords found in the articles after exmination\n",
    "stop_pre = stopwords.words('english') # getting the common english stopwords\n",
    "stop_words = stop_found + stop_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#religion_df = aquire.take_words(religion_articles, stop_words)\n",
    "religion_df = pd.read_pickle('religion_articles')\n",
    "religion_df = religion_df.drop_duplicates('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#science_df = aquire.take_words(science_articles, stop_words)\n",
    "science_df = pd.read_pickle('science_articles')\n",
    "science_df = science_df.drop_duplicates('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Religion</td>\n",
       "      <td>[religion, social-cultural, system, designated...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>African and African-American women in Christia...</td>\n",
       "      <td>[christianity, africa, began, egypt, middle, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Religion and agriculture</td>\n",
       "      <td>[religion, agriculture, closely, associated, s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>American Anglican Church</td>\n",
       "      <td>[anglican, church, north, america, acna, chris...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>American Humanist Association</td>\n",
       "      <td>[american, humanist, association, aha, non-pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1395</td>\n",
       "      <td>Scientific equipment optician</td>\n",
       "      <td>[scientific, equipment, optician, individual, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1396</td>\n",
       "      <td>Volcanologist</td>\n",
       "      <td>[volcanologist, vulcanologist, geologist, stud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1397</td>\n",
       "      <td>Allen Brain Atlas</td>\n",
       "      <td>[allen, mouse, human, brain, atlases, projects...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1398</td>\n",
       "      <td>Allen Institute for Brain Science</td>\n",
       "      <td>[allen, institute, brain, science, seattle-bas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1399</td>\n",
       "      <td>Amsterdam Call for Action on Open Science</td>\n",
       "      <td>[amsterdam, call, action, open, science, docum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  \\\n",
       "0                                              Religion   \n",
       "1     African and African-American women in Christia...   \n",
       "2                              Religion and agriculture   \n",
       "3                              American Anglican Church   \n",
       "4                         American Humanist Association   \n",
       "...                                                 ...   \n",
       "1395                      Scientific equipment optician   \n",
       "1396                                      Volcanologist   \n",
       "1397                                  Allen Brain Atlas   \n",
       "1398                  Allen Institute for Brain Science   \n",
       "1399          Amsterdam Call for Action on Open Science   \n",
       "\n",
       "                                                  words  label  \n",
       "0     [religion, social-cultural, system, designated...      0  \n",
       "1     [christianity, africa, began, egypt, middle, 1...      0  \n",
       "2     [religion, agriculture, closely, associated, s...      0  \n",
       "3     [anglican, church, north, america, acna, chris...      0  \n",
       "4     [american, humanist, association, aha, non-pro...      0  \n",
       "...                                                 ...    ...  \n",
       "1395  [scientific, equipment, optician, individual, ...      1  \n",
       "1396  [volcanologist, vulcanologist, geologist, stud...      1  \n",
       "1397  [allen, mouse, human, brain, atlases, projects...      1  \n",
       "1398  [allen, institute, brain, science, seattle-bas...      1  \n",
       "1399  [amsterdam, call, action, open, science, docum...      1  \n",
       "\n",
       "[1400 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "religion_labeled_df = religion_df.copy()\n",
    "religion_labeled_df['label'] = 0\n",
    "\n",
    "science_labeled_df = science_df.copy()\n",
    "science_labeled_df['label'] = 1\n",
    "\n",
    "#words_df_reduced = pd.concat([religion_labeled_df[:int(len(religion_labeled_df)/10)],\\\n",
    "#                      science_labeled_df[:int(len(science_labeled_df)/10)]], ignore_index=True)\n",
    "words_df_reduced = pd.concat([religion_labeled_df[:700], science_labeled_df[:700]], ignore_index=True)\n",
    "                              \n",
    "labels_df = words_df_reduced['label']\n",
    "words_df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpu = NLPUtilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>science</th>\n",
       "      <th>religion</th>\n",
       "      <th>religious</th>\n",
       "      <th>also</th>\n",
       "      <th>god</th>\n",
       "      <th>book</th>\n",
       "      <th>scientific</th>\n",
       "      <th>research</th>\n",
       "      <th>one</th>\n",
       "      <th>church</th>\n",
       "      <th>...</th>\n",
       "      <th>review</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>information</th>\n",
       "      <th>system</th>\n",
       "      <th>however</th>\n",
       "      <th>john</th>\n",
       "      <th>islam</th>\n",
       "      <th>group</th>\n",
       "      <th>years</th>\n",
       "      <th>based</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Religion</td>\n",
       "      <td>0.040566</td>\n",
       "      <td>0.543287</td>\n",
       "      <td>0.261171</td>\n",
       "      <td>0.040955</td>\n",
       "      <td>0.040272</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059069</td>\n",
       "      <td>0.035598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.03139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030415</td>\n",
       "      <td>0.026056</td>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.075973</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>African and African-American women in Christianity</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023470</td>\n",
       "      <td>0.039923</td>\n",
       "      <td>0.033911</td>\n",
       "      <td>0.006669</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.013043</td>\n",
       "      <td>0.219298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053285</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.005868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Religion and agriculture</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>American Anglican Church</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.017105</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.259163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>American Humanist Association</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009570</td>\n",
       "      <td>0.046511</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.038071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Scientific equipment optician</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Volcanologist</td>\n",
       "      <td>0.023798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.015751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027415</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Allen Brain Atlas</td>\n",
       "      <td>0.022973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070573</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.016720</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.004459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Allen Institute for Brain Science</td>\n",
       "      <td>0.031113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.023895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Amsterdam Call for Action on Open Science</td>\n",
       "      <td>0.223707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039510</td>\n",
       "      <td>0.038656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     science  religion  \\\n",
       "article                                                                  \n",
       "Religion                                            0.040566  0.543287   \n",
       "African and African-American women in Christianity  0.000000  0.023470   \n",
       "Religion and agriculture                            0.000000  0.069755   \n",
       "American Anglican Church                            0.000000  0.001558   \n",
       "American Humanist Association                       0.000000  0.009570   \n",
       "...                                                      ...       ...   \n",
       "Scientific equipment optician                       0.000000  0.000000   \n",
       "Volcanologist                                       0.023798  0.000000   \n",
       "Allen Brain Atlas                                   0.022973  0.000000   \n",
       "Allen Institute for Brain Science                   0.031113  0.000000   \n",
       "Amsterdam Call for Action on Open Science           0.223707  0.000000   \n",
       "\n",
       "                                                    religious      also  \\\n",
       "article                                                                   \n",
       "Religion                                             0.261171  0.040955   \n",
       "African and African-American women in Christianity   0.039923  0.033911   \n",
       "Religion and agriculture                             0.000000  0.040315   \n",
       "American Anglican Church                             0.003028  0.017105   \n",
       "American Humanist Association                        0.046511  0.019358   \n",
       "...                                                       ...       ...   \n",
       "Scientific equipment optician                        0.000000  0.049731   \n",
       "Volcanologist                                        0.000000  0.016018   \n",
       "Allen Brain Atlas                                    0.000000  0.018039   \n",
       "Allen Institute for Brain Science                    0.000000  0.003490   \n",
       "Amsterdam Call for Action on Open Science            0.000000  0.015057   \n",
       "\n",
       "                                                         god      book  \\\n",
       "article                                                                  \n",
       "Religion                                            0.040272  0.005691   \n",
       "African and African-American women in Christianity  0.006669  0.005654   \n",
       "Religion and agriculture                            0.000000  0.000000   \n",
       "American Anglican Church                            0.005311  0.006004   \n",
       "American Humanist Association                       0.038071  0.000000   \n",
       "...                                                      ...       ...   \n",
       "Scientific equipment optician                       0.000000  0.000000   \n",
       "Volcanologist                                       0.015751  0.000000   \n",
       "Allen Brain Atlas                                   0.000000  0.000000   \n",
       "Allen Institute for Brain Science                   0.000000  0.000000   \n",
       "Amsterdam Call for Action on Open Science           0.000000  0.000000   \n",
       "\n",
       "                                                    scientific  research  \\\n",
       "article                                                                    \n",
       "Religion                                              0.020897  0.000000   \n",
       "African and African-American women in Christianity    0.000000  0.005804   \n",
       "Religion and agriculture                              0.000000  0.000000   \n",
       "American Anglican Church                              0.000000  0.000000   \n",
       "American Humanist Association                         0.000000  0.004733   \n",
       "...                                                        ...       ...   \n",
       "Scientific equipment optician                         0.029000  0.000000   \n",
       "Volcanologist                                         0.000000  0.027415   \n",
       "Allen Brain Atlas                                     0.000000  0.070573   \n",
       "Allen Institute for Brain Science                     0.006106  0.023895   \n",
       "Amsterdam Call for Action on Open Science             0.039510  0.038656   \n",
       "\n",
       "                                                         one    church  ...  \\\n",
       "article                                                                 ...   \n",
       "Religion                                            0.059069  0.035598  ...   \n",
       "African and African-American women in Christianity  0.013043  0.219298  ...   \n",
       "Religion and agriculture                            0.000000  0.000000  ...   \n",
       "American Anglican Church                            0.012696  0.259163  ...   \n",
       "American Humanist Association                       0.007091  0.011538  ...   \n",
       "...                                                      ...       ...  ...   \n",
       "Scientific equipment optician                       0.000000  0.000000  ...   \n",
       "Volcanologist                                       0.010268  0.000000  ...   \n",
       "Allen Brain Atlas                                   0.003304  0.000000  ...   \n",
       "Allen Institute for Brain Science                   0.000000  0.000000  ...   \n",
       "Amsterdam Call for Action on Open Science           0.000000  0.000000  ...   \n",
       "\n",
       "                                                      review  spiritual  \\\n",
       "article                                                                   \n",
       "Religion                                            0.004107    0.03139   \n",
       "African and African-American women in Christianity  0.000000    0.00000   \n",
       "Religion and agriculture                            0.000000    0.00000   \n",
       "American Anglican Church                            0.000000    0.00000   \n",
       "American Humanist Association                       0.000000    0.00000   \n",
       "...                                                      ...        ...   \n",
       "Scientific equipment optician                       0.000000    0.00000   \n",
       "Volcanologist                                       0.000000    0.00000   \n",
       "Allen Brain Atlas                                   0.000000    0.00000   \n",
       "Allen Institute for Brain Science                   0.000000    0.00000   \n",
       "Amsterdam Call for Action on Open Science           0.000000    0.00000   \n",
       "\n",
       "                                                    information    system  \\\n",
       "article                                                                     \n",
       "Religion                                               0.000000  0.030415   \n",
       "African and African-American women in Christianity     0.007334  0.000000   \n",
       "Religion and agriculture                               0.000000  0.000000   \n",
       "American Anglican Church                               0.000000  0.000000   \n",
       "American Humanist Association                          0.000000  0.000000   \n",
       "...                                                         ...       ...   \n",
       "Scientific equipment optician                          0.000000  0.000000   \n",
       "Volcanologist                                          0.000000  0.000000   \n",
       "Allen Brain Atlas                                      0.016720  0.005104   \n",
       "Allen Institute for Brain Science                      0.015097  0.006912   \n",
       "Amsterdam Call for Action on Open Science              0.000000  0.014909   \n",
       "\n",
       "                                                     however      john  \\\n",
       "article                                                                  \n",
       "Religion                                            0.026056  0.013743   \n",
       "African and African-American women in Christianity  0.028767  0.000000   \n",
       "Religion and agriculture                            0.000000  0.000000   \n",
       "American Anglican Church                            0.003055  0.003625   \n",
       "American Humanist Association                       0.000000  0.016704   \n",
       "...                                                      ...       ...   \n",
       "Scientific equipment optician                       0.000000  0.100127   \n",
       "Volcanologist                                       0.013588  0.000000   \n",
       "Allen Brain Atlas                                   0.004372  0.000000   \n",
       "Allen Institute for Brain Science                   0.000000  0.000000   \n",
       "Amsterdam Call for Action on Open Science           0.000000  0.000000   \n",
       "\n",
       "                                                       islam     group  \\\n",
       "article                                                                  \n",
       "Religion                                            0.075973  0.026332   \n",
       "African and African-American women in Christianity  0.053285  0.019623   \n",
       "Religion and agriculture                            0.000000  0.000000   \n",
       "American Anglican Church                            0.002358  0.003473   \n",
       "American Humanist Association                       0.000000  0.005334   \n",
       "...                                                      ...       ...   \n",
       "Scientific equipment optician                       0.000000  0.000000   \n",
       "Volcanologist                                       0.000000  0.015448   \n",
       "Allen Brain Atlas                                   0.000000  0.004971   \n",
       "Allen Institute for Brain Science                   0.000000  0.000000   \n",
       "Amsterdam Call for Action on Open Science           0.000000  0.000000   \n",
       "\n",
       "                                                       years     based  \n",
       "article                                                                 \n",
       "Religion                                            0.000000  0.023621  \n",
       "African and African-American women in Christianity  0.006092  0.005868  \n",
       "Religion and agriculture                            0.000000  0.069755  \n",
       "American Anglican Church                            0.004852  0.000000  \n",
       "American Humanist Association                       0.004968  0.000000  \n",
       "...                                                      ...       ...  \n",
       "Scientific equipment optician                       0.000000  0.000000  \n",
       "Volcanologist                                       0.014387  0.000000  \n",
       "Allen Brain Atlas                                   0.004629  0.004459  \n",
       "Allen Institute for Brain Science                   0.000000  0.000000  \n",
       "Amsterdam Call for Action on Open Science           0.000000  0.013026  \n",
       "\n",
       "[1400 rows x 100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = nlpu.TF_IDF(words_df_reduced, 100)\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>science</td>\n",
       "      <td>52.716979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>religion</td>\n",
       "      <td>38.608664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>religious</td>\n",
       "      <td>34.886210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>also</td>\n",
       "      <td>26.213901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>god</td>\n",
       "      <td>26.073406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>john</td>\n",
       "      <td>8.422473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>islam</td>\n",
       "      <td>8.327312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>group</td>\n",
       "      <td>8.310144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>years</td>\n",
       "      <td>8.304601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>based</td>\n",
       "      <td>8.151457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfidf\n",
       "science    52.716979\n",
       "religion   38.608664\n",
       "religious  34.886210\n",
       "also       26.213901\n",
       "god        26.073406\n",
       "...              ...\n",
       "john        8.422473\n",
       "islam       8.327312\n",
       "group       8.310144\n",
       "years       8.304601\n",
       "based       8.151457\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_words_df = pd.DataFrame(tf_idf.sum(axis=0, numeric_only=True).sort_values(ascending = False),\\\n",
    "                                  columns=['tfidf'])\n",
    "important_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't really need the function make_features anymore \n",
    "# features = aquire.make_features(words_df_reduced, important_words_df.reset_index().rename(columns={'index':'words'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With weights, the features matrix is equal to the dataframe tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_weight = tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the version that uses no weights (there is a 1 for every non zero value), we can do the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_no_weight = tf_idf.where(tf_idf<=0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following, we choose to work with weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have hence aquired the data and put it in a dataframe called features. Its rows are the different articles and each column is an important word (according to TF-IDF scores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "import operator\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixUtils():\n",
    "    \n",
    "    @staticmethod\n",
    "    def epsilon_similarity_graph(X: np.ndarray, sigma=1, epsilon=0):\n",
    "        \"\"\" \n",
    "        Fnction to compute the epsilon similarity graph seen in class\n",
    "        Arguments:\n",
    "        X (n x d): coordinates of the n data points in R^d.\n",
    "        sigma (float): width of the kernel\n",
    "        epsilon (float): threshold\n",
    "        Returns:\n",
    "        adjacency (n x n ndarray): adjacency matrix of the graph.\n",
    "        \"\"\"\n",
    "        adjacency = squareform(pdist(X))\n",
    "        adjacency = np.exp((- adjacency**2)/(2 * sigma**2))\n",
    "        adjacency[adjacency < epsilon] = 0\n",
    "        #according to the formula on slide 11 in the spectral clustering lecture, we set the diagonal to 0\n",
    "        np.fill_diagonal(adjacency,0)\n",
    "        return adjacency\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_laplacian(adjacency: np.ndarray, normalize: bool):\n",
    "        \"\"\" \n",
    "        Function to compute the laplacian\n",
    "        Arguments:\n",
    "        adjacency - an adjacency matrix for which to compute the laplacian\n",
    "        normalize - if set to True, the normalized laplacian is returned, otherwise the combinatorial one is returned \n",
    "        Returns:\n",
    "        L (n x n ndarray): combinatorial or symmetric normalized Laplacian.\n",
    "        \"\"\"\n",
    "        degrees_l = np.sum(adjacency,axis=1)\n",
    "        if(not normalize):\n",
    "            degrees = np.zeros(adjacency.shape)\n",
    "            np.fill_diagonal(degrees,degrees_l)\n",
    "            return degrees - adjacency \n",
    "        else:\n",
    "            degrees = np.sqrt(np.array([degrees_l]).T @ np.array([degrees_l]))\n",
    "            L = - adjacency/degrees\n",
    "            np.fill_diagonal(L,np.ones(len(adjacency)))\n",
    "            return L\n",
    "    \n",
    "    @staticmethod\n",
    "    def spectral_decomposition(laplacian: np.ndarray):\n",
    "        \"\"\"\n",
    "        Function to carry out spectral decomposition on a given matrix\n",
    "        Arguments:\n",
    "        laplacian - matrix on which to carry out decomposition\n",
    "        Returns:\n",
    "        lamb (np.array): eigenvalues of the Laplacian\n",
    "        U (np.ndarray): corresponding eigenvectors.\n",
    "        \"\"\"\n",
    "        values, vectors = np.linalg.eig(laplacian)\n",
    "        sorted_indices = np.argsort(values)\n",
    "        return values[sorted_indices], vectors[:,sorted_indices]\n",
    "    \n",
    "    @staticmethod\n",
    "    def GFT(signal: np.ndarray):\n",
    "        \"\"\"\n",
    "        Function to compute the fourier transform of a signal\n",
    "        Arguments:\n",
    "        signal - the signal for which to compute the fourier transform (in the form of an Numpy array)\n",
    "        Returns:\n",
    "        fourier - the fourier transform of the signal provided\n",
    "        \"\"\"\n",
    "        fourier = U.transpose()@signal\n",
    "        return fourier\n",
    "    \n",
    "    @staticmethod\n",
    "    def iGFT(fourier_coefficients: np.ndarray):\n",
    "        \"\"\"\n",
    "        Function to compute the signal from a fourier transform\n",
    "        Arguments:\n",
    "        fourier_coefficients - the fourier coefficients from which to get the signal (in the form of an Numpy array)\n",
    "        Returns:\n",
    "        signal - the signal for the fourier coefficients given\n",
    "        \"\"\"\n",
    "        signal = U@fourier_coefficients\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterUtilities():\n",
    "    \n",
    "    @staticmethod    \n",
    "    def ideal_graph_filter(x: np.ndarray, spectral_response: np.ndarray):\n",
    "        \"\"\"\n",
    "        Function to apply an idea filter to a graph\n",
    "        Arguments:\n",
    "        x - the signal on which to apply the filter\n",
    "        spectral_response - the spectral response of the signal\n",
    "        Returns:\n",
    "        filtered_graph - a filtered signal\n",
    "        \"\"\"\n",
    "        fourier = MatrixUtils().GFT(x);\n",
    "        h = np.diag(spectral_response)\n",
    "        filtered_graph = U@h@fourier\n",
    "        return filtered_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisUtils():\n",
    "    \n",
    "    @staticmethod\n",
    "    def laplacian_eigenmaps(X:np.ndarray, dim: int, sigma: float, epsilon: float, normalize: bool):\n",
    "        \"\"\"\n",
    "        Function to compute the laplacian eigenmap if a given matrix\n",
    "        Arguments:\n",
    "        X - the matrix for which to compute the eigenmaps\n",
    "        dim - the dimension of the data we would like to return\n",
    "        sigma - the sigma parameter for the epsilon similarity graph\n",
    "        epsilon - the epsilon parameter for the epsilon similarity graph\n",
    "        normalize - if set to True, the normalized laplacian is used, otherwise the combinatorial one is used \n",
    "        Returns:\n",
    "        coords (n x dim array): new coordinates for the data points\n",
    "        \"\"\"\n",
    "        adjacency = MatrixUtils().epsilon_similarity_graph(X, sigma, epsilon)\n",
    "        laplacian = MatrixUtils().compute_laplacian(adjacency, normalize)\n",
    "        eigenvalues, eigenvectors = MatrixUtils().spectral_decomposition(np.nan_to_num(laplacian)) \n",
    "        return (eigenvectors[:,1:dim+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring graph properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine(a,b):\n",
    "    if(norm(a) == 0 or norm(b) == 0):\n",
    "        return dot(a,b)\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_a = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.array(\n",
    "    [\n",
    "        [\n",
    "            cosine(features_a[i,:],features_a[j,:]) for i in range(0,features_a.shape[0])\n",
    "        ]\n",
    "        for j in range(0,features_a.shape[0])\n",
    "    ]\n",
    "    ).reshape(features.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(8, 4))\n",
    "plt.title(\"Histogram of cosine similarity between papers\")\n",
    "plt.hist(distances.flatten());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>science</td>\n",
       "      <td>52.716979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>religion</td>\n",
       "      <td>38.608664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>religious</td>\n",
       "      <td>34.886210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>also</td>\n",
       "      <td>26.213901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>god</td>\n",
       "      <td>26.073406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>book</td>\n",
       "      <td>24.822986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>scientific</td>\n",
       "      <td>23.692436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>research</td>\n",
       "      <td>22.570687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>one</td>\n",
       "      <td>21.420285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>church</td>\n",
       "      <td>20.377060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>new</td>\n",
       "      <td>18.943110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>university</td>\n",
       "      <td>18.662818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>world</td>\n",
       "      <td>17.003072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>study</td>\n",
       "      <td>16.529316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>may</td>\n",
       "      <td>16.474153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>first</td>\n",
       "      <td>15.883151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>people</td>\n",
       "      <td>15.558595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>religions</td>\n",
       "      <td>15.077564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>used</td>\n",
       "      <td>14.841717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>christian</td>\n",
       "      <td>14.670851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tfidf\n",
       "science     52.716979\n",
       "religion    38.608664\n",
       "religious   34.886210\n",
       "also        26.213901\n",
       "god         26.073406\n",
       "book        24.822986\n",
       "scientific  23.692436\n",
       "research    22.570687\n",
       "one         21.420285\n",
       "church      20.377060\n",
       "new         18.943110\n",
       "university  18.662818\n",
       "world       17.003072\n",
       "study       16.529316\n",
       "may         16.474153\n",
       "first       15.883151\n",
       "people      15.558595\n",
       "religions   15.077564\n",
       "used        14.841717\n",
       "christian   14.670851"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_words_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.nan_to_num(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(distances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.where(distances>0.6,1,0)\n",
    "np.fill_diagonal(feat, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a graph using the normalized distances\n",
    "graph = nx.from_numpy_matrix(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assessing the giant component size\n",
    "giant_feature = max(nx.connected_component_subgraphs(graph), key=len)\n",
    "print('The giant component of the feature graph has {} nodes and {} edges.'.format(giant_feature.number_of_nodes(), giant_feature.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the average clustering coefficient of our graph\n",
    "nx.average_clustering(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring possible clustering in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixu = MatrixUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(adjacency_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = matrixu.epsilon_similarity_graph(feat, sigma= 10*np.mean(feat), epsilon=0.20)\n",
    "plt.spy(adjacency)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "pr = nx.pagerank(graph)\n",
    "sorted_pr = sorted(pr.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pr[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring possible clustering in the graph after passing it through an ideal filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the laplacian\n",
    "laplacian = matrixu.compute_laplacian(adjacency, normalize=True)\n",
    "lam, U = matrixu.spectral_decomposition(np.nan_to_num(laplacian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.99 / np.max(lam)\n",
    "\n",
    "ideal_tk =  1/(1 + alpha*lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = ideal_graph_filter(adjacency.tolist(),ideal_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_filt = nx.from_numpy_matrix(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'node_color': 'black',\n",
    "    'node_size': 20,\n",
    "    'line_color': 'grey',\n",
    "    'linewidths': 0.2,\n",
    "    'width': 0.3,\n",
    "}\n",
    "nx.draw(graph, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'node_color': 'black',\n",
    "    'node_size': 20,\n",
    "    'line_color': 'grey',\n",
    "    'linewidths': 0.2,\n",
    "    'width': 0.3,\n",
    "}\n",
    "nx.draw(graph_filt, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_features = max(nx.connected_component_subgraphs(graph_filt), key = len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'node_color': 'black',\n",
    "    'node_size': 20,\n",
    "    'line_color': 'grey',\n",
    "    'linewidths': 0.2,\n",
    "    'width': 0.3,\n",
    "}\n",
    "nx.draw(giant_features, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_features.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_filt = epsilon_similarity_graph(filt, sigma= 2*np.mean(feat), epsilon=0.60)\n",
    "plt.spy(adjacency)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the graph obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visu = VisUtils()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian Eigenmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoD_embeddings = visu.laplacian_eigenmaps(adjacency_matrix, dim=2, sigma= 4*np.mean(adjacency_matrix), epsilon=0.40, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(twoD_embeddings[0:800,0], twoD_embeddings[0:800,1], label=1)\n",
    "plt.scatter(twoD_embeddings[800:2650,0], twoD_embeddings[800:2650,1], label=2)\n",
    "plt.title('Graph of Wikipedia Science and Religion articles (done using Laplacian Eigenmaps)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components = 2)\n",
    "x_embed = tsne.fit_transform(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_embed[0:800,0], x_embed[0:800,1], label=1)\n",
    "plt.scatter(x_embed[800:2650,0], x_embed[800:2650,1], label=2)\n",
    "plt.title('Graph of Wikipedia Science and Religion articles (done using tSN-E)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dgl import DGLGraph\n",
    "import dgl.function as fn\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplacianPolynomial(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats: int,\n",
    "                 out_feats: int,\n",
    "                 k: int,\n",
    "                 dropout_prob: float,\n",
    "                 norm=True):\n",
    "        super().__init__()\n",
    "        self._in_feats = in_feats\n",
    "        self._out_feats = out_feats\n",
    "        self._k = k\n",
    "        self._norm = norm\n",
    "        # Contains the weights learned by the Laplacian polynomial\n",
    "        self.pol_weights = nn.Parameter(torch.Tensor(self._k + 1))\n",
    "        # Contains the weights learned by the logistic regression (without bias)\n",
    "        self.logr_weights = nn.Parameter(torch.Tensor(in_feats, out_feats))\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        torch.manual_seed(0)\n",
    "        torch.nn.init.xavier_uniform_(self.logr_weights, gain=0.01)\n",
    "        torch.nn.init.normal_(self.pol_weights, mean=0.0, std=1e-3)\n",
    "\n",
    "    def forward(self, graph, feat):\n",
    "        r\"\"\"Compute graph convolution.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        * Input shape: :math:`(N, *, \\text{in_feats})` where * means any number of additional\n",
    "          dimensions, :math:`N` is the number of nodes.\n",
    "        * Output shape: :math:`(N, *, \\text{out_feats})` where all but the last dimension are\n",
    "          the same shape as the input.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        graph (DGLGraph) : The graph.\n",
    "        feat (torch.Tensor): The input feature\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (torch.Tensor) The output feature\n",
    "        \"\"\"\n",
    "        feat = self.dropout(feat)\n",
    "        graph = graph.local_var()\n",
    "        \n",
    "        # D^(-1/2)\n",
    "        norm = torch.pow(graph.in_degrees().float().clamp(min=1), -0.5)\n",
    "        shp = norm.shape + (1,) * (feat.dim() - 1)\n",
    "        norm = torch.reshape(norm, shp)\n",
    "\n",
    "        # mult W first to reduce the feature size for aggregation.\n",
    "        feat = torch.matmul(feat, self.logr_weights)\n",
    "\n",
    "        result = self.pol_weights[0] * feat.clone()\n",
    "\n",
    "        for i in range(1, self._k + 1):\n",
    "            old_feat = feat.clone()\n",
    "            if self._norm:\n",
    "                feat = feat * norm\n",
    "            graph.ndata['h'] = feat\n",
    "            # Feat is not modified in place\n",
    "            graph.update_all(fn.copy_src(src='h', out='m'),\n",
    "                             fn.sum(msg='m', out='h'))\n",
    "            if self._norm:\n",
    "                graph.ndata['h'] = graph.ndata['h'] * norm\n",
    "\n",
    "            feat = old_feat - graph.ndata['h']\n",
    "            result += self.pol_weights[i] * feat\n",
    "\n",
    "        return result\n",
    "\n",
    "    def extra_repr(self):\n",
    "        \"\"\"Set the extra representation of the module,\n",
    "        which will come into effect when printing the model.\n",
    "        \"\"\"\n",
    "        summary = 'in={_in_feats}, out={_out_feats}'\n",
    "        summary += ', normalization={_norm}'\n",
    "        return summary.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g, features, labels, loss_fcn, train_mask, optimizer):\n",
    "    model.train()  # Activate dropout\n",
    "    \n",
    "    logits = model(g, features)\n",
    "    loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()  # Deactivate dropout\n",
    "    with torch.no_grad():\n",
    "        logits = model(g, features)[mask]  # only compute the evaluation set\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "       \n",
    "def test_articles(model, g, features, mask):\n",
    "    model.eval()  # Deactivate dropout\n",
    "    with torch.no_grad():\n",
    "        logits = model(g, features)[mask] \n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1, x2, y1, y2, idx1, idx2 = train_test_split(\n",
    "    adjacency_matrix, labels_df['label'], range(adjacency_matrix.shape[1]), test_size=0.4)\n",
    "x3, x4, y3, y4, idx3, idx4 = train_test_split(\n",
    "    x2, y2, idx2, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(np.column_stack((idx1, np.ones(len(idx1)).T)), columns = ['idx', 'indices'])\n",
    "train_ = labels_df.merge(train_df, left_index = True, right_on = 'idx', how = 'left').fillna(0)\n",
    "val_df = pd.DataFrame(np.column_stack((idx3, np.ones(len(idx3)).T)), columns = ['idx', 'indices'])\n",
    "val_ = labels_df.merge(val_df, left_index = True, right_on = 'idx', how = 'left').fillna(0)\n",
    "test_df = pd.DataFrame(np.column_stack((idx4, np.ones(len(idx4)).T)), columns = ['idx', 'indices'])\n",
    "test_ = labels_df.merge(val_df, left_index = True, right_on = 'idx', how = 'left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feats = features.shape[1] \n",
    "n_classes = 2\n",
    "pol_order = 3\n",
    "lr = 0.2\n",
    "weight_decay = 5e-6\n",
    "n_epochs = 100\n",
    "p_dropout = 0.8\n",
    "features_ = torch.FloatTensor(features) \n",
    "labels = torch.LongTensor(labels_df['label']) \n",
    "train_mask = torch.BoolTensor(train_['indices'])\n",
    "val_mask = torch.BoolTensor(val_['indices'])\n",
    "test_mask = torch.BoolTensor(test_['indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LaplacianPolynomial(in_feats, n_classes, pol_order, p_dropout)\n",
    "\n",
    "graph = DGLGraph(graph)\n",
    "\n",
    "loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=lr,\n",
    "                             weight_decay=weight_decay)\n",
    "\n",
    "dur = []\n",
    "for epoch in range(n_epochs):\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    loss = train(model, graph, features_, labels, loss_fcn, train_mask, optimizer)\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    acc = evaluate(model, graph, features_, labels, val_mask)\n",
    "    print(\"Epoch {:05d} | Time(s) {:.4f} | Train Loss {:.4f} | Val Accuracy {:.4f}\". format(\n",
    "            epoch, np.mean(dur), loss.item(), acc))\n",
    "\n",
    "print()\n",
    "acc = evaluate(model, graph, features_, labels, test_mask)\n",
    "print(\"Test Accuracy {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_gcn =  model.pol_weights.data.numpy()\n",
    "print(coeff_gcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_graph_filter_response(coeff: np.array, lam: np.ndarray):\n",
    "    \"\"\" Return an array of the same shape as lam.\n",
    "        response[i] is the spectral response at frequency lam[i]. \"\"\"\n",
    "    # Your code here\n",
    "    V = np.vander(lam, len(coeff), increasing=True)\n",
    "    return V@coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(lam, np.abs(polynomial_graph_filter_response(coeff_gcn, lam)))\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('Spectral response (db)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_articles = [\"God\", \"Network Science\", \"Jesus\", \"Quantic physics\"]\n",
    "test_df = take_words(list_articles, is_title = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = make_features(test_df)\n",
    "features_final = np.concatenate((features, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.array([[(np.sum((features_final[i,:]-features_final[j,:])**2)) for i in range(0,features_final.shape[0]) ] for j in range(0,features_final.shape[0])]).reshape(features_final.shape[0],-1)\n",
    "feat = distances/np.max(distances)\n",
    "np.fill_diagonal(feat, 0)\n",
    "graph = nx.from_numpy_array(feat)\n",
    "graph = DGLGraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ = torch.FloatTensor(features_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = np.zeros((len(features)))\n",
    "mask2 = np.ones((len(test)))\n",
    "mask = np.concatenate((mask1,mask2))\n",
    "mask = torch.BoolTensor(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles(model, graph, features_, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pol_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.logr_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cheeger constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Eigengaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = matrixu.compute_laplacian(adjacency_matrix, normalize = False)\n",
    "eigenvalues, eigenvectors = matrixu.spectral_decomposition(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(eigenvalues)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.title('Eigenvalues $L_{comb}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
